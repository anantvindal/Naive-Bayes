{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as s\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devnagri Handwritten characters is a dataset consisting of numbers and letters of the Devnagri Script.<br>\n",
    "We have 46 classes, 1700 images per class to give us a total of 78200 images.<br>\n",
    "Each image is 32x32 black and white image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_data(path_of_folders):\n",
    "    classes=list()\n",
    "    img_array=list()\n",
    "    list_of_folders = os.listdir(path_of_folders)\n",
    "    for folder in list_of_folders:\n",
    "        path = os.path.join(path_of_folders,folder)\n",
    "        list_of_images = os.listdir(path)\n",
    "        for images in list_of_images:\n",
    "            path2 = os.path.join(path,images)\n",
    "            img = plt.imread(path2)\n",
    "            classes.append(str(folder))\n",
    "            img=img.reshape(1,1024)\n",
    "            img_array.extend(img)\n",
    "    img_array = np.array(img_array)\n",
    "    classes = np.array(classes,dtype=str)\n",
    "    classes_n = np.zeros(classes.shape,dtype=int)\n",
    "    img_array = pd.DataFrame(img_array)\n",
    "    l=list(np.unique(classes))\n",
    "    for i in range(len(classes)):\n",
    "        classes_n[i]=l.index(classes[i])\n",
    "    return (img_array,classes,classes_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training data\n",
    "path_of_train_folders = 'D:/Datasets/DevanagariHandwrittenCharacterDataset/Train'\n",
    "raw_data,classes_train_alpha,classes_train_n = Load_data(path_of_train_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load testing data\n",
    "path_of_test_folders = 'D:/Datasets/DevanagariHandwrittenCharacterDataset/Test'\n",
    "test_data,classes_test_alpha,classes_test_n = Load_data(path_of_test_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_copy = raw_data.copy()\n",
    "test_data_copy = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cross validation data\n",
    "cross_val_data=test_data.iloc[0:170]\n",
    "cross_val_classes=list(classes_test_n[0:170])\n",
    "for i in range(1,46):\n",
    "    cross_val_data=cross_val_data.append(test_data.iloc[i*300:i*300+170])\n",
    "    cross_val_classes.extend(classes_test_n[i*300:i*300+170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character_18_da\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Example of an image\n",
    "a=np.array(raw_data.iloc[15000,0:1024],dtype=float)\n",
    "plt.imshow(a.reshape(32,32),cmap='gray')\n",
    "print(classes_train_alpha[15000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data normalisation is an important part of the pre-processing stage. We can use two types of normalisation:-<br>\n",
    "\n",
    "### Z-Score Normalisation\n",
    "<br>\n",
    "$Z = \\frac{x-\\mu}{\\sigma}$\n",
    "<br>\n",
    "\n",
    "### Min-Max Normalisation\n",
    "<br>\n",
    "$Z = \\frac{x-Min}{Max-Min}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-score normalisation\n",
    "#calculate mu for all the features\n",
    "mu_vector = []\n",
    "for i in range(1024):\n",
    "    mu_vector.append(raw_data_copy.iloc[:,i].mean())\n",
    "mu_vector = np.array(mu_vector)\n",
    "std_vector = []\n",
    "for i in range(1024):\n",
    "    std_vector.append(raw_data_copy.iloc[:,i].std())\n",
    "std_vector = np.array(std_vector)\n",
    "\n",
    "std_vector = std_vector.reshape(1024,1)\n",
    "mu_vector = mu_vector.reshape(1024,1)\n",
    "\n",
    "for i in range(1024):\n",
    "    raw_data_copy.iloc[:,i] = raw_data_copy.iloc[:,i]-mu_vector[i]\n",
    "    if std_vector[i]!=0:\n",
    "        raw_data_copy.iloc[:,i] = raw_data_copy.iloc[:,i]/std_vector[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize testing data\n",
    "for i in range(1024):\n",
    "    test_data_copy.iloc[:,i] = test_data_copy.iloc[:,i]-mu_vector[i]\n",
    "    if std_vector[i]!=0:\n",
    "        test_data_copy.iloc[:,i] = test_data_copy.iloc[:,i]/std_vector[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity we are considering our data to follow the Multivariate Normal Distribution<br>\n",
    "The formula for Multivariate-Gaussian PDF is:-<br>\n",
    "\n",
    "${\\large \\frac{e^{-0.5[x-\\mu]^T \\Sigma^{-1}_i [x-\\mu]}}{\\sqrt{2\\pi}^k \\sqrt{|\\Sigma_i|}}}$\n",
    "\n",
    "is applicable only when $\\Sigma$ is non-singular\n",
    "\n",
    "This condition put on $\\Sigma$ being non singular is due to the fact that we have to calculate the inverse of the class covariance matrix ($\\Sigma$)<br>\n",
    "This is the biggest challenge<br>\n",
    "\n",
    "Let us see why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  "
     ]
    }
   ],
   "source": [
    "#calculate covariance matrix and check determinants\n",
    "cov_matrices = []\n",
    "for i in range(46):\n",
    "    cov_matrices.append(raw_data_copy.iloc[i*1700:(i+1)*1700].cov())\n",
    "    print(np.linalg.det(cov_matrices[-1]),end='  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the given data we have 32x32 = 1024 dimensions<br>\n",
    "if you check the data you will see that most of the columns are Linearly Dependant or sparse. This makes our covariance matrix singular. To overcome this issue, we use a dimensionality reduction technique called PCA or Principal Component Analysis.<br>\n",
    "\n",
    "PCA projects our data along a combination of dimensions which have maximum variance in them.<br>\n",
    "For further reference read this wonderful article on $\\href{https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c}{PCA}$\n",
    "\n",
    "There are various ways to apply PCA. We will do so with the help of Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407, 1024)\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = raw_data_copy.cov()\n",
    "q,lamb,qt=np.linalg.svd(cov_matrix)\n",
    "trace=sum(lamb)\n",
    "indices=[]\n",
    "f_vector=[]\n",
    "sm=0\n",
    "for i in range(len(lamb)):\n",
    "    sm+=lamb[i]\n",
    "    #we can specify the amount of variance we want to preserve\n",
    "    if sm/trace<0.99:\n",
    "        indices.append(np.argmax(q[i]))\n",
    "        f_vector.append(q[:,i])\n",
    "    else:\n",
    "        break\n",
    "f_vector = np.array(f_vector)\n",
    "print(f_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.858221139319408e-171\n"
     ]
    }
   ],
   "source": [
    "new_data = (raw_data_copy@f_vector.T)\n",
    "new_data = pd.DataFrame(new_data)\n",
    "print(np.linalg.det(new_data.cov()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after PCA the determinant is close to 0 which might result in an error during the calculation of inverse of $\\Sigma$ <br>\n",
    "\n",
    "Now we will apply another dimensionality technique called RDA or Regularised Discriminant Analysis on our Covariance matrix<br>\n",
    "\n",
    "RDA is somewhat of a mixture of the LDA and QDA<br>\n",
    "Go back to our Multivariate-Gaussian PDF and check how we are calculating it. LDA assumes that <br>\n",
    "$\\Sigma_0 = \\Sigma_1 = \\Sigma_2 = \\dots = \\Sigma_k = \\Sigma_{pooled}$  \n",
    "\n",
    "Whereas QDA assumes that all class covariance matrices are unique<br>\n",
    "RDA is a tradeoff between both the assumptions<br>\n",
    "RDA = $\\alpha$ LDA + $(1-\\alpha)$ QDA <br>\n",
    "$\\alpha \\, \\epsilon \\,  [0,1]$\n",
    "<br>\n",
    "Although we will use a modified version of RDA:- <br>\n",
    "$\\Sigma_i ^ r =\\sum_{i=0}^{k} (1-\\gamma)\\Sigma_i + \\gamma \\sigma I_{MxM}$\n",
    "<br>\n",
    "$\\sigma = trace( \\Sigma_{pooled})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate covariance matrices for all the classes after PCA\n",
    "cov_matrices_ap = []\n",
    "for i in range(46):\n",
    "    cov_matrices_ap.append(new_data.iloc[i*1700:(i+1)*1700].cov())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Sigma_{pooled} = \\frac{\\sum_{i=0}^{k} (N_i-1)\\Sigma_i}{\\sum_{i=0}^{k} N_i - k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "#calculate pooled covariance\n",
    "pooled_cov=0\n",
    "for i in cov_matrices_ap:\n",
    "    pooled_cov = 1699*i + pooled_cov\n",
    "pooled_cov = pooled_cov/(78200-46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha \\,\\&\\, \\gamma$ are Hyperparameters<br>\n",
    "$\\therefore$ We need to tune them with the help of Cross-validation data<br>\n",
    "We can perform either a grid search or a random search for the Hyperparameters as there doesn not exist any heuristic for choosing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calc_ans(likelihood,data_size,classes):\n",
    "    ans=[]\n",
    "    for i in range(data_size):\n",
    "        m=[]\n",
    "        for j in range(46):\n",
    "            m.append((likelihood[j][i],j))\n",
    "        ans.append((i,min(m)))\n",
    "    count=0\n",
    "    for i in range(data_size):\n",
    "        if int(ans[i][1][1])==classes[i]:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_data = cross_val_data@f_vector.T\n",
    "cross_val_data = pd.DataFrame(cross_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [03:15<00:00,  6.51s/it]\n"
     ]
    }
   ],
   "source": [
    "vals=[]\n",
    "sigma=np.trace(pooled_cov)/pooled_cov.shape[0]\n",
    "for i in tqdm(range(30)):\n",
    "    lam=np.random.uniform()\n",
    "    rda=[]\n",
    "    for j in cov_matrices_ap:\n",
    "        rda.append(j*lam + (1-lam)*pooled_cov)\n",
    "    gamma=np.random.uniform()\n",
    "    rda_dash=[]\n",
    "    for k in range(46):\n",
    "        rda_dash.append((1-gamma)*rda[k] + gamma*sigma*np.identity(rda[k].shape[0]))\n",
    "    likelihood_cross_val=[]\n",
    "    for l in range(46):\n",
    "        #likelihood probabilities can get very small\n",
    "        #Therefore we use -log to solve the problem of underflow\n",
    "        likelihood_cross_val.append(-np.log(s.multivariate_normal.pdf(cross_val_data,cross_val_data.iloc[i*170:(i+1)*170].mean(),rda_dash[l])))\n",
    "    count=Calc_ans(likelihood_cross_val,cross_val_data.shape[0],cross_val_classes)\n",
    "    vals.append([count,lam,gamma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5573, 0.5924238472072683, 0.9067736504261744]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the values\n",
    "ind=np.argmax(vals)\n",
    "vals[ind//3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use these values in training\n",
    "lam=vals[ind//3][1]\n",
    "rda=[]\n",
    "for j in cov_matrices_ap:\n",
    "    rda.append(j*lam + (1-lam)*pooled_cov)\n",
    "gamma=vals[ind//3][2]\n",
    "rda_dash=[]\n",
    "sigma=np.sum(np.diag(pooled_cov))/pooled_cov.shape[0]\n",
    "for k in range(46):\n",
    "    rda_dash.append((1-gamma)*rda[k] + gamma*sigma*np.identity(rda[k].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training likelihood\n",
    "likelihood_train=[]\n",
    "for i in range(46):\n",
    "    a = -np.log(s.multivariate_normal.pdf(new_data,new_data.iloc[i*1700:(i+1)*1700].mean(),rda_dash[i]))\n",
    "    likelihood_train.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836764705882353\n"
     ]
    }
   ],
   "source": [
    "#training accuracy\n",
    "count_train = Calc_ans(likelihood_train,new_data.shape[0],classes_train_n)\n",
    "print(count_train/new_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_copy = test_data_copy@f_vector.T\n",
    "test_data_copy = pd.DataFrame(test_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing likelihood\n",
    "likelihood_test=[]\n",
    "for i in range(46):\n",
    "    likelihood_test.append(-np.log(s.multivariate_normal.pdf(test_data_copy,new_data.iloc[i*1700:(i+1)*1700].mean(),rda_dash[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8261594202898551\n"
     ]
    }
   ],
   "source": [
    "#testing accuracy\n",
    "count_test = Calc_ans(likelihood_test,test_data.shape[0],classes_test_n)\n",
    "print(count_test/test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
